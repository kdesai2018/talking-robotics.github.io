---
layout: talk
type: "Talk"
date: 2022-01-19
name: "Dimosthenis Kontogiorgos"
teaser: "Mutual Understanding in Situated Interactions with Conversational User Interfaces: Theory, Studies, and Computation"
link: "/all_talks/dimosthenis"
author_profile: true
# register: https://us02web.zoom.us/meeting/register/tZYscO-oqjMoGdM2nJ1W64CNPK3NS5gG6OjD
---
## Speaker

Dimos has a background in Human-Computer Interaction and currently works at the Linguistics group at Potsdam University in Germany as a PostDoctoral Researcher. During his PhD at KTH Royal Institute of Technology, he has been a Visiting Research Scholar at Microsoft Research in Seattle, and at the University of Southern California’s Institute for Creative Technologies in Los Angeles. He is interested in modelling how humans co-produce utterances in interaction within the principles known as audience design, and how conversational user interfaces and robots can simulate such adaptation strategies in interactions with humans.

Speaker Links: [Website](kth.se/profile/diko) - [Google Scholar](https://scholar.google.ca/citations?user=PItN4BQAAAAJ)

<iframe width="560" height="315" src="https://www.youtube.com/embed/WLWoXu5BtR4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
---

## Abstract
In this talk, I will discuss empirical findings from recent research in the investigation of human behavioural signals in response to miscommunication with conversational user interfaces. The increasing use of robots in real-world applications will inevitably cause users to encounter more failures in interactions with machines. Robots should be able to infer conversational failures by detecting human users’ behavioural and social signals. Our findings so far indicate that human-like robots augment users’ reactions to failures, in comparison to less human-like smart-speakers. The results further suggest that several nonverbal behaviours are consistently present in responses to robots’ failures, whereas, linguistic features appear to be task-dependent. I will discuss how we believe such findings may generalise to new domains, and how autonomous robots may identify opportunities to detect and recover from failures in interactions with humans.

---

#### Papers covered during the talk
* **Kontogiorgos D.** & Gustafson, J. Measuring Collaboration Load With Pupillary Responses-Implications for the Design of Instructions in Task-Oriented HRI. 2021. Frontiers in Psychology.

* **Kontogiorgos, D.**, van Waveren, S., Wallberg, O., Pereira, A., Leite, I., & Gustafson, J. Embodiment effects in interactions with failing robots. 2020. In CHI conference on human factors in computing systems.

* **Kontogiorgos, D.**, Pereira, A., Sahindal, B., van Waveren, S., & Gustafson, J. Behavioural responses to robot conversational failures. 2020. In HRI International Conference on Human-Robot Interaction.

* **Kontogiorgos, D.**, Tran, M., Gustafson, J., & Soleymani, M. A Systematic Cross-Corpus Analysis of Human Reactions to Robot Conversational Failures. 2021. In ICMI International Conference on Multimodal Interaction.
